<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="LMQL: A query language for programming (large) language models.">
  <meta name="keywords" content="GPT-3, language models, LMQL, programming language, query language, ChatGPT">
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=0"/>
  
  <!-- Primary Meta Tags -->
  <title>LMQL becomes simpler and adds llama.cpp</title>
  <meta name="title" content="LMQL becomes simpler and adds llama.cpp">
  <meta name="description" content="Today we are releasing LMQL 0.0.6.5. This update contains a major simplification of the LMQL syntax, moving it much closer to standard Python. It also includes a llama.cpp based inference backend, several bug fixes and other minor improvements.">

  <!-- Open Graph / Facebook -->
  <meta property="og:type" content="website">
  <meta property="og:url" content="https://lmql.ai/">
  <meta property="og:title" content="LMQL becomes simpler and adds llama.cpp">
  <meta property="og:description" content="Today we are releasing LMQL 0.0.6.5. This update contains a major simplification of the LMQL syntax, moving it much closer to standard Python. It also includes a llama.cpp based inference backend, several bug fixes and other minor improvements.">
  <meta property="og:image" content="https://lmql.ai/static/images/lmql-social.png">

  <!-- Twitter -->
  <meta property="twitter:card" content="summary_large_image">
  <meta property="twitter:url" content="https://lmql.ai/">
  <meta property="twitter:title" content="LMQL becomes simpler and adds llama.cpp">
  <meta property="twitter:description" content="Today we are releasing LMQL 0.0.6.5. This update contains a major simplification of the LMQL syntax, moving it much closer to standard Python. It also includes a llama.cpp based inference backend, several bug fixes and other minor improvements.">
  <meta property="twitter:image" content="https://lmql.ai/static/images/lmql-social.png"">
  
  
  <!--  set relative path to be / -->
  <base href="/">

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">
  <link rel="stylesheet" href="./static/css/val.gen.css">
  <link rel="stylesheet" href="./static/css/lmql.css">
  <link rel="stylesheet" href="./static/css/highlight.min.css">
  <script src="https://kit.fontawesome.com/06bb68d804.js" crossorigin="anonymous"></script>

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="./static/js/highlight.min.js"></script>
  <script src="./static/js/lmql.js"></script>
  <script>
    var openPlaygroundElement = null;

function getPlaygroundUrl(next) {
    const host = window.location.host;
    console.log("next is", next)
    if (next) {
      return "https://next.lmql.ai/playground"
    }
    if (host.includes("lmql.ai")) {
        return "https://lmql.ai/playground";
    } else if (host.startsWith("localhost") || host.startsWith("127.0.0.1")) {
        return "http://localhost:3000/playground";
    } else {
        return "https://lbeurerkellner.github.io/green-gold-dachshund-web/playground";
    }
}

function closePlaygroundSnippet() {
    if (openPlaygroundElement) {
        openPlaygroundElement.innerHTML = openPlaygroundElement.originalHTML;
        openPlaygroundElement.classList.remove('playground');
        openPlaygroundElement.style.height = 'auto';

        // show model output div if it exists
        let next = openPlaygroundElement.nextElementSibling;
        while(next.tagName !== 'DIV' && next) {
            next = next.nextElementSibling;
        }

        if (next.classList.contains('highlight-model-output')) {
            next.style.display = 'block';
        }

            openPlaygroundElement = null;
        }
}

function openPlaygroundSnippet(link, snippet) {
    closePlaygroundSnippet();

    const playground = getPlaygroundUrl(snippet.includes("next-"));
    console.log("playground url: " + playground);

    // this is a that was clicked, replace parent div with iframe (temporarily)
    const container = link.parentElement;
    container.classList.add('playground');
    const iframe = document.createElement('iframe');
    iframe.src = ""
    iframe.src = playground + '?embed=' + snippet + ".json"
    iframe.style.width = '100%';
    iframe.style.height = '100%';
    iframe.style.border = 'none';
    
    const height = Math.max(400, container.clientHeight);
    container.originalHTML = container.innerHTML;
    container.innerHTML = '';
    container.style.height = height + 'px';
    container.appendChild(iframe);

    // hide the model output div if it exists
    let next = container.nextElementSibling;
    while(next.tagName !== 'DIV' && next) {
        next = next.nextElementSibling;
    }

    if (next.classList.contains('highlight-model-output')) {
        next.style.display = 'none';
    }

    openPlaygroundElement = container;
}
  </script>

  <!-- Cloudflare Web Analytics --><script defer src='https://static.cloudflareinsights.com/beacon.min.js' data-cf-beacon='{"token": "f7d2a6b1a0624c51ae4dab9a4239b77d"}'></script><!-- End Cloudflare Web Analytics -->
</head>
<body>
  <div class="topnav">
    <a href="/">
      <img src="./static/images/lmql-text.png" alt="LMQL logo" class="logo">
    </a>
    <a href="https://discord.gg/7eJP4fcyNT" class="hide-on-small">
      üí¨
      Discord
    </a>
    <a href="blog">
      üìù
      Blog
    </a>
    <a href="https://docs.lmql.ai">
      üìñ
      Docs
    </a>
    <a href="https://github.com/eth-sri/lmql">
      üì¶
      GitHub</a>
  </div>


<section class="section blog " id="release-0.0.6.5">
    <div class="container is-max-desktop">
      <!-- Abstract. -->
      <div class="columns is-centered has-text-centered">
        <div class="column">
          <h5 class="title is-2 has-text-left" style="margin-bottom: 2pt;">
            <a href="blog/release-0.0.6.5.html" class="anchor">
                LMQL becomes simpler and adds llama.cpp
            </a>
          </h5>
          <div class="content has-text-justified">
          <div class="authors">
            <div class="is-size-5 publication-authors">
              <span class="author-block">
            <a href="mailto:hello@lmql.ai">LMQL Team</a>
        </span>
            </div>
          </div>
            <div class="date">
                Thu, Jul 13, 2023
            </div>
            <section id="lmql-becomes-simpler-and-adds-llama-cpp">

<p>Today we are releasing LMQL 0.0.6.5. This update contains a major simplification of the LMQL syntax, moving it much closer to standard Python. It also includes a <code class="docutils literal notranslate"><span class="pre">llama.cpp</span></code> based inference backend, several bug fixes and other minor improvements.</p>
<p>You can try the latest version of LMQL in your browser at <a class="reference external" href="https://lmql.ai/playground">lmql.ai/playground</a> or install it via <code class="docutils literal notranslate"><span class="pre">pip</span> <span class="pre">install</span> <span class="pre">lmql</span></code>.</p>
<section id="one-line-is-all-it-takes">
<h2>One Line Is All It Takes<a class="headerlink" href="#one-line-is-all-it-takes" title="Permalink to this heading">¬∂</a></h2>
<p>Most notably, 0.0.6.5 comes with several simplifications of the core syntax of LMQL. Of course, all changes are backwards compatible, so you can continue to use your existing query code and move to the new version without any changes.</p>
<p>With this, we aim to minimize syntactic overhead, employing sensible defaults to enable more concise programs like the following:</p>
<p></p><div class="highlight lmql"><button href="" onclick="openPlaygroundSnippet(this, 'doc-snippets/blog-release-0-0-6-5-md-simple-syntax')">Open In Playground</button><pre><span></span><span class="s2">"One line is all it takes [CONTINUATION]"</span>
</pre></div>
<div class="highlight-model-output notranslate"><div class="highlight">One line is all it takes <span class="variable val1"><span class="variable-name">CONTINUATION</span> Fallin' in love with me.</span></div></div><p></p>
<p><strong>Sensible Defaults</strong> This is possible because LMQL now automatically assumes <code class="docutils literal notranslate"><span class="pre">argmax</span></code> and <code class="docutils literal notranslate"><span class="pre">openai/text-davinci-003</span></code> as (configurable) default model. If you prefer to use
a different model or custom decoder settings, you can still specify them explicitly, e.g. in the <code class="docutils literal notranslate"><span class="pre">@lmql.query</span></code> decorator function as demonstrated later in this post.</p>
<p>Without any additional configuration, the simple query code above translates to a full LMQL program like this:</p>
<p></p><div class="highlight lmql"><button href="" onclick="openPlaygroundSnippet(this, 'doc-snippets/blog-release-0-0-6-5-md-simple-syntax-default')">Open In Playground</button><pre><span></span><span class="kp">argmax</span> <span class="s2">"One line is all it takes [CONTINUATION]"</span> <span class="kn">from</span> <span class="s2">"openai/text-davinci-003"</span>
</pre></div>
<p></p>
<br>
<section id="inline-constraints">
<h3>Inline Constraints<a class="headerlink" href="#inline-constraints" title="Permalink to this heading">¬∂</a></h3>
<p>LMQL now allows you to specify several inline <code class="docutils literal notranslate"><span class="pre">where</span></code> constraints. This enables constraints that refer to local program variables, which means constraints can now be dependent on previous model outputs.</p>
<p></p><div class="highlight lmql"><button href="" onclick="openPlaygroundSnippet(this, 'doc-snippets/blog-release-0-0-6-5-md-list-with-array')">Open In Playground</button><pre><span></span><span class="s2">"A list of awesome Dua Lipa songs:</span><span class="se">\n</span><span class="s2">"</span>
<span class="n">songs</span> <span class="o">=</span> <span class="p">[]</span>

<p><span class="s2">&quot;- New Rules</span><span class="se">\n</span><span class="s2">&quot;</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">4</span><span class="p">):</span>
    <span class="s2">&quot;-[SONG]</span><span class="se">\n</span><span class="s2">&quot;</span> <span class="kp">where</span> <span class="n">STOPS_BEFORE</span><span class="p">(</span><span class="n">SONG</span><span class="p">,</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">songs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">SONG</span><span class="p">)</span></p>
<p><span class="s2">&quot;Out of these, my favorite is[FAVORITE]&quot;</span> <span class="kp">where</span> <span class="n">FAVORITE</span> <span class="ow">in</span> <span class="n">songs</span>
</pre></div></p>
<div class="highlight-model-output notranslate"><div class="highlight">A list of awesome Dua Lipa songs:‚èé
- New Rules
- <span class="variable val1"><span class="variable-name">SONG</span> Don't Start Now</span>
- <span class="variable val1"><span class="variable-name">SONG</span> IDGAF</span>
- <span class="variable val1"><span class="variable-name">SONG</span> Be the One</span>
- <span class="variable val1"><span class="variable-name">SONG</span> Blow Your Mind (Mwah)</span>
Out of these, my favorite is <span class="variable val2"><span class="variable-name">FAVORITE</span> Don't Start Now</span></div></div><p></p>
<p>Note also how in this example LMQL code now reads much more like standard Python code, without any additional level of indentation.</p>
<br>
</section>
<section id="lmql-query-functions">
<h3><code class="docutils literal notranslate"><span class="pre">@lmql.query</span></code> functions<a class="headerlink" href="#lmql-query-functions" title="Permalink to this heading">¬∂</a></h3>
<p>The overhauled syntax also makes LMQL much  easier on the eyes when used with the <code class="docutils literal notranslate"><span class="pre">@lmql.query</span></code> <a class="reference external" href="https://docs.lmql.ai/en/stable/python/python.html">function decorator in Python</a>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span id="1-1"><span class="kn">import</span> <span class="nn">lmql</span>
</span><span id="1-2"><span class="kn">import</span> <span class="nn">json</span>
</span><span id="1-3">
</span><span id="1-4"><span class="nd">@lmql</span><span class="o">.</span><span class="n">query</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="s2">"openai/text-curie-001"</span><span class="p">,</span> <span class="n">temperature</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>
</span><span id="1-5"><span class="k">def</span> <span class="nf">summarize</span><span class="p">():</span> <span class="s1">'''lmql</span>
</span><span id="1-6"><span class="s1">    """</span>
</span><span id="1-7"><span class="s1">    Provide a summary of Dua Lipa, the pop icon:</span>
</span><span id="1-8"><span class="s1">    {{</span>
</span><span id="1-9"><span class="s1">      "name": "[STRING_VALUE]",</span>
</span><span id="1-10"><span class="s1">      "chart_position": [INT_VALUE],</span>
</span><span id="1-11"><span class="s1">      "top_songs": [[</span>
</span><span id="1-12"><span class="s1">         "[STRING_VALUE]",</span>
</span><span id="1-13"><span class="s1">         "[STRING_VALUE]"</span>
</span><span id="1-14"><span class="s1">      ]]</span>
</span><span id="1-15"><span class="s1">    }}</span>
</span><span id="1-16"><span class="s1">    """ where STOPS_BEFORE(STRING_VALUE, '"') and INT(INT_VALUE) and len(TOKENS(INT_VALUE)) &lt; 3</span>
</span><span id="1-17"><span class="s1">    </span>
</span><span id="1-18"><span class="s1">    return json.loads(context.prompt.split("pop icon:",1)[1])'''</span>
</span><span id="1-19">
</span><span id="1-20"><span class="nb">print</span><span class="p">(</span><span class="n">summarize</span><span class="p">())</span> <span class="c1"># {'name': 'Dua Lipa', 'chart_position': 3415, 'top_songs': ['New Rules', 'Havana']}</span>
</span></pre></div>
</div>
<br>
</section>
<section id="lmql-f-lambda-functions">
<h3><code class="docutils literal notranslate"><span class="pre">lmql.F</span></code> Lambda Functions<a class="headerlink" href="#lmql-f-lambda-functions" title="Permalink to this heading">¬∂</a></h3>
<p>Based on LMQL‚Äôs new minimal syntax, we introduce a novel and concise way to write LLM-based lambda functions. This offers a lightweight entryway to get started with integrated small LLM-based utilities in your code, without having to write a full LMQL program.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span id="1-1"><span class="kn">import</span> <span class="nn">lmql</span>
</span><span id="1-2">
</span><span id="1-3"><span class="n">summarize</span> <span class="o">=</span> <span class="n">lmql</span><span class="o">.</span><span class="n">F</span><span class="p">(</span><span class="s2">"Summarize the following in a few words: </span><span class="si">{data}</span><span class="s2">: [SUMMARY]"</span><span class="p">)</span>
</span><span id="1-4"><span class="n">main_subject</span> <span class="o">=</span> <span class="n">lmql</span><span class="o">.</span><span class="n">F</span><span class="p">(</span><span class="s2">"What is the main subject (noun) of the following text? </span><span class="si">{data}</span><span class="s2">: [SUBJECT]"</span><span class="p">,</span> 
</span><span id="1-5">                      <span class="s2">"len(TOKENS(SUBJECT)) &lt; 20"</span><span class="p">)</span>
</span><span id="1-6">
</span><span id="1-7"><span class="n">text</span> <span class="o">=</span> <span class="s2">"In LMQL, users can specify high-level, logical constraints ..."</span>
</span><span id="1-8">
</span><span id="1-9"><span class="n">summarize</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">text</span><span class="p">)</span> <span class="c1"># LMQL enables high-level constraints to be enforced during text </span>
</span><span id="1-10">                     <span class="c1"># generation, simplifying multi-part prompting and integration.</span>
</span><span id="1-11"><span class="n">main_subject</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">text</span><span class="p">)</span> <span class="c1"># Language Model Query Language (LMQL)</span>
</span></pre></div>
</div>
<br>
<br>
</section>
</section>
<section id="llama-cpp-inference-backend">
<h2><code class="docutils literal notranslate"><span class="pre">llama.cpp</span></code> Inference Backend<a class="headerlink" href="#llama-cpp-inference-backend" title="Permalink to this heading">¬∂</a></h2>
<p>LMQL now also fully integrates with the excellent <a class="reference external" href="https://github.com/ggerganov/llama.cpp">llama.cpp</a> C++ implementation of a number of Transformer-based language models.</p>
<p>Using <code class="docutils literal notranslate"><span class="pre">llama.cpp</span></code> from LMQL is as simple as specifying it in the <code class="docutils literal notranslate"><span class="pre">from</span></code> clause of a query:</p>
<p></p><div class="highlight lmql"><button href="" onclick="openPlaygroundSnippet(this, 'doc-snippets/blog-release-0-0-6-5-md-llama-cpp-blog')">Open In Playground</button><pre><span></span><span class="kp">argmax</span> <span class="s2">"Say 'this is a test':[RESPONSE]"</span> <span class="kn">from</span> <span class="s2">"llama.cpp:&lt;PATH TO WEIGHTS&gt;.bin"</span>
</pre></div>
<p></p>
<p>We support, both, in-process loading of <code class="docutils literal notranslate"><span class="pre">llama.cpp</span></code>, as well as remote inference via <code class="docutils literal notranslate"><span class="pre">lmql</span> <span class="pre">serve-model</span></code>. To learn more about <code class="docutils literal notranslate"><span class="pre">llama.cpp</span></code> and how to use it with LMQL, check out the corresponding chapter in the LMQL <a class="reference external" href="https://docs.lmql.ai/en/latest/language/llama.cpp.html">documentation</a>.</p>
<br>
</section>
<section id="other-changes">
<h2>Other Changes<a class="headerlink" href="#other-changes" title="Permalink to this heading">¬∂</a></h2>
<ul class="simple">
<li><p>LMQL now includes a <code class="docutils literal notranslate"><span class="pre">random</span></code> model backend, which randomly samples tokens from the GPT-2 vocabulary. This is useful for debugging and testing purposes and can be used for data generation in the context of highly constrained query programs.</p></li>
<li><p>Two caching issues have been fixed, avoiding cache collisions which could lead to repeated model outputs.</p></li>
<li><p>More robust query string parsing, allowing for <a class="reference external" href="https://docs.lmql.ai/en/stable/language/scripted_prompts.html#escaping">robust escaping</a> of special characters <code class="docutils literal notranslate"><span class="pre">[</span></code>, <code class="docutils literal notranslate"><span class="pre">]</span></code>, <code class="docutils literal notranslate"><span class="pre">{</span></code> and <code class="docutils literal notranslate"><span class="pre">}</span></code>.</p></li>
<li><p>Added support for <code class="docutils literal notranslate"><span class="pre">transformers</span></code> based Llama models and the associated (fast) implementation of HF tokenizers.</p></li>
<li><p>Simplified Azure OpenAI support, see the relevant chapter in the <a class="reference external" href="https://docs.lmql.ai/en/stable/language/azure.html">documentation</a>.</p></li>
</ul>
<p>We thank community members <a class="reference external" href="https://github.com/minosvasilias">@minosvasilias</a> and <a class="reference external" href="https://github.com/CircArgs">@CircArgs</a> for their contribution to this release.</p>
</section>
</section>


          </div>
        </div>
    </div>
  </section>
    <a class='blog see-all' href="/blog">See all blog posts</a>

<section class="section custom-footer">
  <div class="container is-max-desktop content">
    <div class="columns">
      <div class="column" style="text-align: left;">
        LMQL is a project by the <a href="https://www.sri.inf.ethz.ch/">Secure, Reliable, and Intelligent Systems Lab</a> at ETH Z√ºrich.<br/>
        <img src="static/images/institution-logos.svg"/>
      </div>
      <div class="column" style="text-align: left;">
        Site template adapted from <a href="http://nerfies.github.io/">Nerfies</a> by Keunhong Park et al. and uses <a href="https://bulma.io/">Bulma</a>.<br/>
        Last updated on Fri, Aug 18, 7:46 PM (UTC)<br/>
      </div>
    </div>
  </div>
</section>

</body>
</html>
